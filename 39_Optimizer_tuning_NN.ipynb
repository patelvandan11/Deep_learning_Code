{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df=pd.read_csv('diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Pregnancies</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.129459</td>\n",
       "      <td>0.141282</td>\n",
       "      <td>-0.081672</td>\n",
       "      <td>-0.073535</td>\n",
       "      <td>0.017683</td>\n",
       "      <td>-0.033523</td>\n",
       "      <td>0.544341</td>\n",
       "      <td>0.221898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Glucose</th>\n",
       "      <td>0.129459</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.152590</td>\n",
       "      <td>0.057328</td>\n",
       "      <td>0.331357</td>\n",
       "      <td>0.221071</td>\n",
       "      <td>0.137337</td>\n",
       "      <td>0.263514</td>\n",
       "      <td>0.466581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BloodPressure</th>\n",
       "      <td>0.141282</td>\n",
       "      <td>0.152590</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.207371</td>\n",
       "      <td>0.088933</td>\n",
       "      <td>0.281805</td>\n",
       "      <td>0.041265</td>\n",
       "      <td>0.239528</td>\n",
       "      <td>0.065068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SkinThickness</th>\n",
       "      <td>-0.081672</td>\n",
       "      <td>0.057328</td>\n",
       "      <td>0.207371</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.436783</td>\n",
       "      <td>0.392573</td>\n",
       "      <td>0.183928</td>\n",
       "      <td>-0.113970</td>\n",
       "      <td>0.074752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Insulin</th>\n",
       "      <td>-0.073535</td>\n",
       "      <td>0.331357</td>\n",
       "      <td>0.088933</td>\n",
       "      <td>0.436783</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.197859</td>\n",
       "      <td>0.185071</td>\n",
       "      <td>-0.042163</td>\n",
       "      <td>0.130548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMI</th>\n",
       "      <td>0.017683</td>\n",
       "      <td>0.221071</td>\n",
       "      <td>0.281805</td>\n",
       "      <td>0.392573</td>\n",
       "      <td>0.197859</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.140647</td>\n",
       "      <td>0.036242</td>\n",
       "      <td>0.292695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <td>-0.033523</td>\n",
       "      <td>0.137337</td>\n",
       "      <td>0.041265</td>\n",
       "      <td>0.183928</td>\n",
       "      <td>0.185071</td>\n",
       "      <td>0.140647</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.033561</td>\n",
       "      <td>0.173844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.544341</td>\n",
       "      <td>0.263514</td>\n",
       "      <td>0.239528</td>\n",
       "      <td>-0.113970</td>\n",
       "      <td>-0.042163</td>\n",
       "      <td>0.036242</td>\n",
       "      <td>0.033561</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.238356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outcome</th>\n",
       "      <td>0.221898</td>\n",
       "      <td>0.466581</td>\n",
       "      <td>0.065068</td>\n",
       "      <td>0.074752</td>\n",
       "      <td>0.130548</td>\n",
       "      <td>0.292695</td>\n",
       "      <td>0.173844</td>\n",
       "      <td>0.238356</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Pregnancies   Glucose  BloodPressure  SkinThickness  \\\n",
       "Pregnancies                  1.000000  0.129459       0.141282      -0.081672   \n",
       "Glucose                      0.129459  1.000000       0.152590       0.057328   \n",
       "BloodPressure                0.141282  0.152590       1.000000       0.207371   \n",
       "SkinThickness               -0.081672  0.057328       0.207371       1.000000   \n",
       "Insulin                     -0.073535  0.331357       0.088933       0.436783   \n",
       "BMI                          0.017683  0.221071       0.281805       0.392573   \n",
       "DiabetesPedigreeFunction    -0.033523  0.137337       0.041265       0.183928   \n",
       "Age                          0.544341  0.263514       0.239528      -0.113970   \n",
       "Outcome                      0.221898  0.466581       0.065068       0.074752   \n",
       "\n",
       "                           Insulin       BMI  DiabetesPedigreeFunction  \\\n",
       "Pregnancies              -0.073535  0.017683                 -0.033523   \n",
       "Glucose                   0.331357  0.221071                  0.137337   \n",
       "BloodPressure             0.088933  0.281805                  0.041265   \n",
       "SkinThickness             0.436783  0.392573                  0.183928   \n",
       "Insulin                   1.000000  0.197859                  0.185071   \n",
       "BMI                       0.197859  1.000000                  0.140647   \n",
       "DiabetesPedigreeFunction  0.185071  0.140647                  1.000000   \n",
       "Age                      -0.042163  0.036242                  0.033561   \n",
       "Outcome                   0.130548  0.292695                  0.173844   \n",
       "\n",
       "                               Age   Outcome  \n",
       "Pregnancies               0.544341  0.221898  \n",
       "Glucose                   0.263514  0.466581  \n",
       "BloodPressure             0.239528  0.065068  \n",
       "SkinThickness            -0.113970  0.074752  \n",
       "Insulin                  -0.042163  0.130548  \n",
       "BMI                       0.036242  0.292695  \n",
       "DiabetesPedigreeFunction  0.033561  0.173844  \n",
       "Age                       1.000000  0.238356  \n",
       "Outcome                   0.238356  1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.iloc[:,:-1].values\n",
    "y=df.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scalar=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=scalar.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. how select appropiate optimizers\n",
    "2. no. of nodes in layer\n",
    "3. how to select no.. of layers\n",
    "4. all in one model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda3\\envs\\TF_D\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(30,input_dim=8,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3220 - loss: 0.8223   \n",
      "Epoch 2/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4310 - loss: 0.7438 \n",
      "Epoch 3/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5723 - loss: 0.6819 \n",
      "Epoch 4/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6465 - loss: 0.6422 \n",
      "Epoch 5/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7073 - loss: 0.6151 \n",
      "Epoch 6/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7228 - loss: 0.5873 \n",
      "Epoch 7/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7142 - loss: 0.5716 \n",
      "Epoch 8/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7812 - loss: 0.5226 \n",
      "Epoch 9/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7619 - loss: 0.5353 \n",
      "Epoch 10/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7383 - loss: 0.5196 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x22c25863fd0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,batch_size=32,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7252 - loss: 0.5402 - val_accuracy: 0.7987 - val_loss: 0.4929\n",
      "Epoch 2/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7779 - loss: 0.5070 - val_accuracy: 0.7922 - val_loss: 0.4854\n",
      "Epoch 3/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7726 - loss: 0.4979 - val_accuracy: 0.7922 - val_loss: 0.4789\n",
      "Epoch 4/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8089 - loss: 0.4700 - val_accuracy: 0.7987 - val_loss: 0.4729\n",
      "Epoch 5/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7919 - loss: 0.4815 - val_accuracy: 0.8117 - val_loss: 0.4698\n",
      "Epoch 6/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7865 - loss: 0.4720 - val_accuracy: 0.8117 - val_loss: 0.4672\n",
      "Epoch 7/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7737 - loss: 0.4645 - val_accuracy: 0.8117 - val_loss: 0.4647\n",
      "Epoch 8/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8152 - loss: 0.4523 - val_accuracy: 0.8182 - val_loss: 0.4625\n",
      "Epoch 9/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7797 - loss: 0.4761 - val_accuracy: 0.8117 - val_loss: 0.4602\n",
      "Epoch 10/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7816 - loss: 0.4800 - val_accuracy: 0.8117 - val_loss: 0.4572\n",
      "Epoch 11/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8013 - loss: 0.4446 - val_accuracy: 0.8117 - val_loss: 0.4561\n",
      "Epoch 12/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7657 - loss: 0.4711 - val_accuracy: 0.8182 - val_loss: 0.4552\n",
      "Epoch 13/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7858 - loss: 0.4566 - val_accuracy: 0.8182 - val_loss: 0.4539\n",
      "Epoch 14/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7896 - loss: 0.4760 - val_accuracy: 0.8182 - val_loss: 0.4537\n",
      "Epoch 15/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7533 - loss: 0.4902 - val_accuracy: 0.8182 - val_loss: 0.4526\n",
      "Epoch 16/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7530 - loss: 0.4738 - val_accuracy: 0.8182 - val_loss: 0.4524\n",
      "Epoch 17/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7995 - loss: 0.4416 - val_accuracy: 0.8182 - val_loss: 0.4515\n",
      "Epoch 18/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8002 - loss: 0.4338 - val_accuracy: 0.8182 - val_loss: 0.4503\n",
      "Epoch 19/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7972 - loss: 0.4305 - val_accuracy: 0.8182 - val_loss: 0.4509\n",
      "Epoch 20/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7911 - loss: 0.4248 - val_accuracy: 0.8117 - val_loss: 0.4520\n",
      "Epoch 21/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7611 - loss: 0.4681 - val_accuracy: 0.8052 - val_loss: 0.4523\n",
      "Epoch 22/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7792 - loss: 0.4581 - val_accuracy: 0.8052 - val_loss: 0.4519\n",
      "Epoch 23/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7907 - loss: 0.4459 - val_accuracy: 0.8052 - val_loss: 0.4514\n",
      "Epoch 24/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7868 - loss: 0.4510 - val_accuracy: 0.8117 - val_loss: 0.4494\n",
      "Epoch 25/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7842 - loss: 0.4670 - val_accuracy: 0.8117 - val_loss: 0.4495\n",
      "Epoch 26/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7951 - loss: 0.4369 - val_accuracy: 0.8117 - val_loss: 0.4495\n",
      "Epoch 27/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7811 - loss: 0.4423 - val_accuracy: 0.8117 - val_loss: 0.4498\n",
      "Epoch 28/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7760 - loss: 0.4368 - val_accuracy: 0.8117 - val_loss: 0.4491\n",
      "Epoch 29/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7788 - loss: 0.4394 - val_accuracy: 0.8117 - val_loss: 0.4487\n",
      "Epoch 30/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7970 - loss: 0.4313 - val_accuracy: 0.8117 - val_loss: 0.4490\n",
      "Epoch 31/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7932 - loss: 0.4254 - val_accuracy: 0.8117 - val_loss: 0.4496\n",
      "Epoch 32/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7889 - loss: 0.4412 - val_accuracy: 0.8117 - val_loss: 0.4482\n",
      "Epoch 33/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7910 - loss: 0.4241 - val_accuracy: 0.8117 - val_loss: 0.4480\n",
      "Epoch 34/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7763 - loss: 0.4423 - val_accuracy: 0.8247 - val_loss: 0.4478\n",
      "Epoch 35/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8034 - loss: 0.4112 - val_accuracy: 0.8182 - val_loss: 0.4471\n",
      "Epoch 36/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7718 - loss: 0.4558 - val_accuracy: 0.8182 - val_loss: 0.4473\n",
      "Epoch 37/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7777 - loss: 0.4313 - val_accuracy: 0.8247 - val_loss: 0.4474\n",
      "Epoch 38/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7887 - loss: 0.4060 - val_accuracy: 0.8182 - val_loss: 0.4472\n",
      "Epoch 39/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8054 - loss: 0.4151 - val_accuracy: 0.8182 - val_loss: 0.4488\n",
      "Epoch 40/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7961 - loss: 0.4171 - val_accuracy: 0.8182 - val_loss: 0.4494\n",
      "Epoch 41/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7826 - loss: 0.4378 - val_accuracy: 0.8182 - val_loss: 0.4489\n",
      "Epoch 42/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7528 - loss: 0.4489 - val_accuracy: 0.8182 - val_loss: 0.4487\n",
      "Epoch 43/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7919 - loss: 0.4408 - val_accuracy: 0.8182 - val_loss: 0.4486\n",
      "Epoch 44/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7764 - loss: 0.4422 - val_accuracy: 0.8182 - val_loss: 0.4490\n",
      "Epoch 45/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7748 - loss: 0.4361 - val_accuracy: 0.8117 - val_loss: 0.4490\n",
      "Epoch 46/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8013 - loss: 0.4203 - val_accuracy: 0.8117 - val_loss: 0.4493\n",
      "Epoch 47/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7729 - loss: 0.4552 - val_accuracy: 0.8052 - val_loss: 0.4491\n",
      "Epoch 48/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7958 - loss: 0.4339 - val_accuracy: 0.8052 - val_loss: 0.4486\n",
      "Epoch 49/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7888 - loss: 0.4096 - val_accuracy: 0.8247 - val_loss: 0.4478\n",
      "Epoch 50/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7553 - loss: 0.4655 - val_accuracy: 0.8117 - val_loss: 0.4489\n",
      "Epoch 51/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7694 - loss: 0.4380 - val_accuracy: 0.8117 - val_loss: 0.4492\n",
      "Epoch 52/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7826 - loss: 0.4143 - val_accuracy: 0.8117 - val_loss: 0.4508\n",
      "Epoch 53/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7789 - loss: 0.4391 - val_accuracy: 0.8117 - val_loss: 0.4506\n",
      "Epoch 54/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8146 - loss: 0.3955 - val_accuracy: 0.8117 - val_loss: 0.4513\n",
      "Epoch 55/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7689 - loss: 0.4652 - val_accuracy: 0.8182 - val_loss: 0.4489\n",
      "Epoch 56/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7801 - loss: 0.4327 - val_accuracy: 0.8182 - val_loss: 0.4494\n",
      "Epoch 57/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7872 - loss: 0.4243 - val_accuracy: 0.8052 - val_loss: 0.4480\n",
      "Epoch 58/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7857 - loss: 0.4148 - val_accuracy: 0.8182 - val_loss: 0.4476\n",
      "Epoch 59/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8042 - loss: 0.4006 - val_accuracy: 0.8182 - val_loss: 0.4488\n",
      "Epoch 60/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7954 - loss: 0.4308 - val_accuracy: 0.8117 - val_loss: 0.4476\n",
      "Epoch 61/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7634 - loss: 0.4443 - val_accuracy: 0.8052 - val_loss: 0.4479\n",
      "Epoch 62/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7771 - loss: 0.4384 - val_accuracy: 0.8052 - val_loss: 0.4479\n",
      "Epoch 63/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7939 - loss: 0.4317 - val_accuracy: 0.8117 - val_loss: 0.4478\n",
      "Epoch 64/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7999 - loss: 0.4031 - val_accuracy: 0.8052 - val_loss: 0.4481\n",
      "Epoch 65/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8006 - loss: 0.4111 - val_accuracy: 0.8117 - val_loss: 0.4482\n",
      "Epoch 66/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7716 - loss: 0.4378 - val_accuracy: 0.8182 - val_loss: 0.4485\n",
      "Epoch 67/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8002 - loss: 0.4235 - val_accuracy: 0.8117 - val_loss: 0.4480\n",
      "Epoch 68/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8043 - loss: 0.4121 - val_accuracy: 0.8182 - val_loss: 0.4479\n",
      "Epoch 69/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8198 - loss: 0.4049 - val_accuracy: 0.8117 - val_loss: 0.4487\n",
      "Epoch 70/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7920 - loss: 0.4175 - val_accuracy: 0.8117 - val_loss: 0.4485\n",
      "Epoch 71/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7857 - loss: 0.4281 - val_accuracy: 0.8117 - val_loss: 0.4477\n",
      "Epoch 72/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7864 - loss: 0.4276 - val_accuracy: 0.8052 - val_loss: 0.4467\n",
      "Epoch 73/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7927 - loss: 0.4159 - val_accuracy: 0.8182 - val_loss: 0.4487\n",
      "Epoch 74/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7858 - loss: 0.4363 - val_accuracy: 0.8182 - val_loss: 0.4474\n",
      "Epoch 75/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7783 - loss: 0.4264 - val_accuracy: 0.8117 - val_loss: 0.4482\n",
      "Epoch 76/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7932 - loss: 0.4148 - val_accuracy: 0.8182 - val_loss: 0.4489\n",
      "Epoch 77/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7841 - loss: 0.4449 - val_accuracy: 0.8052 - val_loss: 0.4479\n",
      "Epoch 78/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7902 - loss: 0.4383 - val_accuracy: 0.8117 - val_loss: 0.4478\n",
      "Epoch 79/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7990 - loss: 0.4129 - val_accuracy: 0.8182 - val_loss: 0.4494\n",
      "Epoch 80/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7874 - loss: 0.4394 - val_accuracy: 0.8247 - val_loss: 0.4492\n",
      "Epoch 81/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8319 - loss: 0.4032 - val_accuracy: 0.8117 - val_loss: 0.4488\n",
      "Epoch 82/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7888 - loss: 0.4347 - val_accuracy: 0.8182 - val_loss: 0.4476\n",
      "Epoch 83/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8062 - loss: 0.4187 - val_accuracy: 0.8182 - val_loss: 0.4477\n",
      "Epoch 84/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7981 - loss: 0.4086 - val_accuracy: 0.8182 - val_loss: 0.4488\n",
      "Epoch 85/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8107 - loss: 0.4128 - val_accuracy: 0.8117 - val_loss: 0.4491\n",
      "Epoch 86/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8202 - loss: 0.3983 - val_accuracy: 0.8182 - val_loss: 0.4489\n",
      "Epoch 87/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7955 - loss: 0.4325 - val_accuracy: 0.8182 - val_loss: 0.4480\n",
      "Epoch 88/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7941 - loss: 0.4263 - val_accuracy: 0.8117 - val_loss: 0.4494\n",
      "Epoch 89/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8272 - loss: 0.3971 - val_accuracy: 0.8117 - val_loss: 0.4473\n",
      "Epoch 90/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7968 - loss: 0.4167 - val_accuracy: 0.8182 - val_loss: 0.4477\n",
      "Epoch 91/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8163 - loss: 0.3953 - val_accuracy: 0.8247 - val_loss: 0.4491\n",
      "Epoch 92/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8285 - loss: 0.3910 - val_accuracy: 0.8247 - val_loss: 0.4487\n",
      "Epoch 93/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8028 - loss: 0.4284 - val_accuracy: 0.8182 - val_loss: 0.4465\n",
      "Epoch 94/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8295 - loss: 0.3848 - val_accuracy: 0.8182 - val_loss: 0.4461\n",
      "Epoch 95/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8047 - loss: 0.4086 - val_accuracy: 0.8117 - val_loss: 0.4461\n",
      "Epoch 96/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8062 - loss: 0.4152 - val_accuracy: 0.8247 - val_loss: 0.4475\n",
      "Epoch 97/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7882 - loss: 0.4223 - val_accuracy: 0.8182 - val_loss: 0.4485\n",
      "Epoch 98/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8353 - loss: 0.3644 - val_accuracy: 0.8247 - val_loss: 0.4468\n",
      "Epoch 99/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8059 - loss: 0.4245 - val_accuracy: 0.8247 - val_loss: 0.4479\n",
      "Epoch 100/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8207 - loss: 0.4146 - val_accuracy: 0.8247 - val_loss: 0.4470\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x22c258ac850>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,batch_size=32,epochs=100,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. how select appropiate optimizers\n",
    "2. no. of nodes in layer\n",
    "3. how to select no.. of layers\n",
    "4. all in one model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kerastuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model=Sequential()\n",
    "    model.add(Dense(30,input_dim=8,activation='relu'))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    optimizer=hp.Choice('optimizer',values=['adam','sgd','rmsprop','adadelta','adagrad'])\n",
    "    model.compile(loss='binary_crossentropy',metrics=['accuracy'],optimizer=optimizer)\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from .\\untitled_project\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tuner=kt.RandomSearch(build_model,objective='val_accuracy',max_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(x_train, y_train, epochs=5, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in .\\untitled_project\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 4 summary\n",
      "Hyperparameters:\n",
      "optimizer: sgd\n",
      "Score: 0.6688311696052551\n",
      "\n",
      "Trial 3 summary\n",
      "Hyperparameters:\n",
      "optimizer: adadelta\n",
      "Score: 0.5389610528945923\n",
      "\n",
      "Trial 2 summary\n",
      "Hyperparameters:\n",
      "optimizer: adagrad\n",
      "Score: 0.3896103799343109\n",
      "\n",
      "Trial 0 summary\n",
      "Hyperparameters:\n",
      "optimizer: adam\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Anaconda3\\envs\\TF_D\\lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 274, in _try_run_and_update_trial\n",
      "    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n",
      "  File \"c:\\Anaconda3\\envs\\TF_D\\lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 239, in _run_and_update_trial\n",
      "    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n",
      "  File \"c:\\Anaconda3\\envs\\TF_D\\lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 314, in run_trial\n",
      "    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n",
      "  File \"c:\\Anaconda3\\envs\\TF_D\\lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 233, in _build_and_fit_model\n",
      "    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n",
      "  File \"c:\\Anaconda3\\envs\\TF_D\\lib\\site-packages\\keras_tuner\\src\\engine\\hypermodel.py\", line 149, in fit\n",
      "    return model.fit(*args, **kwargs)\n",
      "  File \"c:\\Anaconda3\\envs\\TF_D\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"c:\\Anaconda3\\envs\\TF_D\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py\", line 737, in binary_crossentropy\n",
      "    raise ValueError(\n",
      "ValueError: Arguments `target` and `output` must have the same rank (ndim). Received: target.shape=(None,), output.shape=(None, 32)\n",
      "\n",
      "\n",
      "Trial 1 summary\n",
      "Hyperparameters:\n",
      "optimizer: rmsprop\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Anaconda3\\envs\\TF_D\\lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 274, in _try_run_and_update_trial\n",
      "    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n",
      "  File \"c:\\Anaconda3\\envs\\TF_D\\lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 239, in _run_and_update_trial\n",
      "    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n",
      "  File \"c:\\Anaconda3\\envs\\TF_D\\lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 314, in run_trial\n",
      "    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n",
      "  File \"c:\\Anaconda3\\envs\\TF_D\\lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 233, in _build_and_fit_model\n",
      "    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n",
      "  File \"c:\\Anaconda3\\envs\\TF_D\\lib\\site-packages\\keras_tuner\\src\\engine\\hypermodel.py\", line 149, in fit\n",
      "    return model.fit(*args, **kwargs)\n",
      "  File \"c:\\Anaconda3\\envs\\TF_D\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"c:\\Anaconda3\\envs\\TF_D\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py\", line 737, in binary_crossentropy\n",
      "    raise ValueError(\n",
      "ValueError: Arguments `target` and `output` must have the same rank (ndim). Received: target.shape=(None,), output.shape=(None, 32)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'optimizer': 'sgd'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner.get_best_hyperparameters()[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda3\\envs\\TF_D\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "A total of 2 objects could not be loaded. Example error message for object <Dense name=dense, built=True>:\n\nThe shape of the target variable and the shape of the target value in `variable.assign(value)` must match. variable.shape=(8, 30), Received: value.shape=(8, 32). Target variable: <Variable path=sequential/dense/kernel, shape=(8, 30), dtype=float32, value=[[ 0.22848585  0.10763946  0.2554576   0.3562083   0.25300947 -0.05768156\n  -0.23173088 -0.35214004  0.31415364  0.18608227 -0.26966166 -0.37537575\n   0.26577213  0.37279007  0.22679439 -0.26035425 -0.1493464   0.34869227\n  -0.2833783   0.20007494 -0.2057545  -0.02106783 -0.29966962 -0.3537774\n   0.37981823 -0.36384758  0.3205463   0.28547087  0.06486234 -0.36001563]\n [ 0.16164234 -0.18634942  0.25442925  0.32265356 -0.24106474  0.04283482\n  -0.04967612 -0.21970353  0.34981284  0.0979777   0.26051334 -0.12330446\n   0.23986366 -0.12099057  0.3926842   0.36290845 -0.1760659  -0.37059236\n   0.10427937  0.02975756 -0.21945171  0.2922217  -0.31439418 -0.07082969\n  -0.21958159 -0.3168952  -0.3741993   0.19837043  0.11326173 -0.07016027]\n [ 0.29407093 -0.10341963 -0.09364626  0.02951124  0.34061697 -0.27688175\n   0.19926563 -0.18842173  0.2579051  -0.35463327 -0.04234606 -0.27845582\n   0.2971522  -0.2837458   0.17777231 -0.08275464  0.09702227  0.28452262\n   0.18026623  0.20471844 -0.077847   -0.03568164 -0.22064029 -0.31741112\n  -0.0825986   0.1904724  -0.35475823 -0.25748456 -0.04800057 -0.04058498]\n [-0.18968856 -0.0720107  -0.2444034  -0.11787409  0.270439   -0.15972437\n   0.35060766  0.38600174  0.18644795 -0.00695291  0.06681725  0.10304311\n  -0.00285125  0.39056984 -0.3360184  -0.39093068  0.3464915  -0.23775347\n   0.20771006  0.2845628   0.34184137 -0.22203928  0.34427425 -0.02526605\n   0.15369657  0.00248876  0.12307975  0.25606832 -0.19586718  0.10899606]\n [-0.0103201   0.24147788  0.32752654 -0.05719793  0.25172213  0.24868265\n  -0.0293391  -0.21298149 -0.27255148  0.13896057  0.37827525 -0.18397766\n  -0.38535744 -0.11638933 -0.09500074  0.2366856   0.30526307 -0.3772173\n   0.17435989 -0.17222627  0.12425193 -0.18840562 -0.1480106   0.38542643\n   0.18030712 -0.09400105 -0.08544755  0.29704633 -0.03990695  0.1613588 ]\n [-0.28645635 -0.23547436 -0.0095689  -0.2568282   0.25353512  0.29096588\n  -0.02436849  0.32646486 -0.24014626 -0.14122403  0.33690098 -0.08146438\n  -0.2322292   0.31663898 -0.36824226 -0.1811378  -0.03585187 -0.01251885\n  -0.199086   -0.18519637  0.06317797 -0.11152843  0.18602559 -0.16568945\n   0.12531385  0.20600954  0.20009288 -0.2465787   0.37497416  0.37281272]\n [ 0.16582975  0.20749804  0.31586596  0.09017679  0.22732082  0.36027887\n   0.01004383 -0.26794797  0.03219971  0.30320063 -0.38358632 -0.04472816\n  -0.18355551  0.3054715   0.08579183  0.0314472   0.22929117  0.3959038\n  -0.37428892 -0.21645771 -0.0949907   0.18437907 -0.00614604  0.30659053\n  -0.22708844 -0.14279869 -0.11193249 -0.17633525 -0.14543998 -0.0094541 ]\n [ 0.22955123  0.33157232 -0.26638025  0.23294863  0.35375693 -0.16360758\n  -0.25845486 -0.02624914 -0.13767865  0.0062854   0.3164954   0.21445885\n   0.34206465 -0.02285534 -0.3157985   0.263433    0.3335391  -0.1334703\n  -0.18272333  0.02213135  0.24029955  0.2796571   0.05101696 -0.01729906\n  -0.18209     0.05490774  0.31177375  0.33219203  0.2523699   0.04712796]]>\n\nList of objects that could not be loaded:\n[<Dense name=dense, built=True>, <Dense name=dense_1, built=True>]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_best_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_models\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Anaconda3\\envs\\TF_D\\lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py:400\u001b[0m, in \u001b[0;36mTuner.get_best_models\u001b[1;34m(self, num_models)\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the best model(s), as determined by the tuner's objective.\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \n\u001b[0;32m    384\u001b[0m \u001b[38;5;124;03mThe models are loaded with the weights corresponding to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;124;03m    List of trained model instances sorted from the best to the worst.\u001b[39;00m\n\u001b[0;32m    398\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;66;03m# Method only exists in this class for the docstring override.\u001b[39;00m\n\u001b[1;32m--> 400\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_best_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_models\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Anaconda3\\envs\\TF_D\\lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:366\u001b[0m, in \u001b[0;36mBaseTuner.get_best_models\u001b[1;34m(self, num_models)\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the best model(s), as determined by the objective.\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \n\u001b[0;32m    353\u001b[0m \u001b[38;5;124;03mThis method is for querying the models trained during the search.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    363\u001b[0m \u001b[38;5;124;03m    List of trained models sorted from the best to the worst.\u001b[39;00m\n\u001b[0;32m    364\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    365\u001b[0m best_trials \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mget_best_trials(num_models)\n\u001b[1;32m--> 366\u001b[0m models \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_model(trial) \u001b[38;5;28;01mfor\u001b[39;00m trial \u001b[38;5;129;01min\u001b[39;00m best_trials]\n\u001b[0;32m    367\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m models\n",
      "File \u001b[1;32mc:\\Anaconda3\\envs\\TF_D\\lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:366\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the best model(s), as determined by the objective.\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \n\u001b[0;32m    353\u001b[0m \u001b[38;5;124;03mThis method is for querying the models trained during the search.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    363\u001b[0m \u001b[38;5;124;03m    List of trained models sorted from the best to the worst.\u001b[39;00m\n\u001b[0;32m    364\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    365\u001b[0m best_trials \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mget_best_trials(num_models)\n\u001b[1;32m--> 366\u001b[0m models \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m trial \u001b[38;5;129;01min\u001b[39;00m best_trials]\n\u001b[0;32m    367\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m models\n",
      "File \u001b[1;32mc:\\Anaconda3\\envs\\TF_D\\lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py:331\u001b[0m, in \u001b[0;36mTuner.load_model\u001b[1;34m(self, trial)\u001b[0m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;66;03m# Reload best checkpoint.\u001b[39;00m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;66;03m# Only load weights to avoid loading `custom_objects`.\u001b[39;00m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m maybe_distribute(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribution_strategy):\n\u001b[1;32m--> 331\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_checkpoint_fname\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrial_id\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Anaconda3\\envs\\TF_D\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Anaconda3\\envs\\TF_D\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:631\u001b[0m, in \u001b[0;36m_raise_loading_failure\u001b[1;34m(error_msgs, warn_only)\u001b[0m\n\u001b[0;32m    629\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(msg)\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 631\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[1;31mValueError\u001b[0m: A total of 2 objects could not be loaded. Example error message for object <Dense name=dense, built=True>:\n\nThe shape of the target variable and the shape of the target value in `variable.assign(value)` must match. variable.shape=(8, 30), Received: value.shape=(8, 32). Target variable: <Variable path=sequential/dense/kernel, shape=(8, 30), dtype=float32, value=[[ 0.22848585  0.10763946  0.2554576   0.3562083   0.25300947 -0.05768156\n  -0.23173088 -0.35214004  0.31415364  0.18608227 -0.26966166 -0.37537575\n   0.26577213  0.37279007  0.22679439 -0.26035425 -0.1493464   0.34869227\n  -0.2833783   0.20007494 -0.2057545  -0.02106783 -0.29966962 -0.3537774\n   0.37981823 -0.36384758  0.3205463   0.28547087  0.06486234 -0.36001563]\n [ 0.16164234 -0.18634942  0.25442925  0.32265356 -0.24106474  0.04283482\n  -0.04967612 -0.21970353  0.34981284  0.0979777   0.26051334 -0.12330446\n   0.23986366 -0.12099057  0.3926842   0.36290845 -0.1760659  -0.37059236\n   0.10427937  0.02975756 -0.21945171  0.2922217  -0.31439418 -0.07082969\n  -0.21958159 -0.3168952  -0.3741993   0.19837043  0.11326173 -0.07016027]\n [ 0.29407093 -0.10341963 -0.09364626  0.02951124  0.34061697 -0.27688175\n   0.19926563 -0.18842173  0.2579051  -0.35463327 -0.04234606 -0.27845582\n   0.2971522  -0.2837458   0.17777231 -0.08275464  0.09702227  0.28452262\n   0.18026623  0.20471844 -0.077847   -0.03568164 -0.22064029 -0.31741112\n  -0.0825986   0.1904724  -0.35475823 -0.25748456 -0.04800057 -0.04058498]\n [-0.18968856 -0.0720107  -0.2444034  -0.11787409  0.270439   -0.15972437\n   0.35060766  0.38600174  0.18644795 -0.00695291  0.06681725  0.10304311\n  -0.00285125  0.39056984 -0.3360184  -0.39093068  0.3464915  -0.23775347\n   0.20771006  0.2845628   0.34184137 -0.22203928  0.34427425 -0.02526605\n   0.15369657  0.00248876  0.12307975  0.25606832 -0.19586718  0.10899606]\n [-0.0103201   0.24147788  0.32752654 -0.05719793  0.25172213  0.24868265\n  -0.0293391  -0.21298149 -0.27255148  0.13896057  0.37827525 -0.18397766\n  -0.38535744 -0.11638933 -0.09500074  0.2366856   0.30526307 -0.3772173\n   0.17435989 -0.17222627  0.12425193 -0.18840562 -0.1480106   0.38542643\n   0.18030712 -0.09400105 -0.08544755  0.29704633 -0.03990695  0.1613588 ]\n [-0.28645635 -0.23547436 -0.0095689  -0.2568282   0.25353512  0.29096588\n  -0.02436849  0.32646486 -0.24014626 -0.14122403  0.33690098 -0.08146438\n  -0.2322292   0.31663898 -0.36824226 -0.1811378  -0.03585187 -0.01251885\n  -0.199086   -0.18519637  0.06317797 -0.11152843  0.18602559 -0.16568945\n   0.12531385  0.20600954  0.20009288 -0.2465787   0.37497416  0.37281272]\n [ 0.16582975  0.20749804  0.31586596  0.09017679  0.22732082  0.36027887\n   0.01004383 -0.26794797  0.03219971  0.30320063 -0.38358632 -0.04472816\n  -0.18355551  0.3054715   0.08579183  0.0314472   0.22929117  0.3959038\n  -0.37428892 -0.21645771 -0.0949907   0.18437907 -0.00614604  0.30659053\n  -0.22708844 -0.14279869 -0.11193249 -0.17633525 -0.14543998 -0.0094541 ]\n [ 0.22955123  0.33157232 -0.26638025  0.23294863  0.35375693 -0.16360758\n  -0.25845486 -0.02624914 -0.13767865  0.0062854   0.3164954   0.21445885\n   0.34206465 -0.02285534 -0.3157985   0.263433    0.3335391  -0.1334703\n  -0.18272333  0.02213135  0.24029955  0.2796571   0.05101696 -0.01729906\n  -0.18209     0.05490774  0.31177375  0.33219203  0.2523699   0.04712796]]>\n\nList of objects that could not be loaded:\n[<Dense name=dense, built=True>, <Dense name=dense_1, built=True>]"
     ]
    }
   ],
   "source": [
    "model = tuner.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │           \u001b[38;5;34m270\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m31\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">905</span> (3.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m905\u001b[0m (3.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">301</span> (1.18 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m301\u001b[0m (1.18 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">604</span> (2.36 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m604\u001b[0m (2.36 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8140 - loss: 0.4096 - val_accuracy: 0.8247 - val_loss: 0.4473\n",
      "Epoch 2/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7963 - loss: 0.4255 - val_accuracy: 0.8182 - val_loss: 0.4469\n",
      "Epoch 3/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7904 - loss: 0.4352 - val_accuracy: 0.8247 - val_loss: 0.4475\n",
      "Epoch 4/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8220 - loss: 0.3996 - val_accuracy: 0.8182 - val_loss: 0.4472\n",
      "Epoch 5/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8164 - loss: 0.4045 - val_accuracy: 0.8182 - val_loss: 0.4489\n",
      "Epoch 6/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8109 - loss: 0.4124 - val_accuracy: 0.8182 - val_loss: 0.4477\n",
      "Epoch 7/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7966 - loss: 0.4305 - val_accuracy: 0.8247 - val_loss: 0.4482\n",
      "Epoch 8/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8118 - loss: 0.4062 - val_accuracy: 0.8247 - val_loss: 0.4468\n",
      "Epoch 9/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8079 - loss: 0.4066 - val_accuracy: 0.8247 - val_loss: 0.4461\n",
      "Epoch 10/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8010 - loss: 0.4318 - val_accuracy: 0.8247 - val_loss: 0.4471\n",
      "Epoch 11/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8112 - loss: 0.4117 - val_accuracy: 0.8247 - val_loss: 0.4479\n",
      "Epoch 12/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8210 - loss: 0.3977 - val_accuracy: 0.8182 - val_loss: 0.4478\n",
      "Epoch 13/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7916 - loss: 0.4279 - val_accuracy: 0.8247 - val_loss: 0.4479\n",
      "Epoch 14/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7844 - loss: 0.4306 - val_accuracy: 0.8247 - val_loss: 0.4474\n",
      "Epoch 15/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8201 - loss: 0.3991 - val_accuracy: 0.8117 - val_loss: 0.4475\n",
      "Epoch 16/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8062 - loss: 0.4044 - val_accuracy: 0.8117 - val_loss: 0.4473\n",
      "Epoch 17/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8361 - loss: 0.3833 - val_accuracy: 0.8182 - val_loss: 0.4471\n",
      "Epoch 18/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8159 - loss: 0.3964 - val_accuracy: 0.8247 - val_loss: 0.4468\n",
      "Epoch 19/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8256 - loss: 0.3958 - val_accuracy: 0.8117 - val_loss: 0.4481\n",
      "Epoch 20/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8208 - loss: 0.3964 - val_accuracy: 0.8247 - val_loss: 0.4486\n",
      "Epoch 21/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8128 - loss: 0.3903 - val_accuracy: 0.8247 - val_loss: 0.4481\n",
      "Epoch 22/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8236 - loss: 0.3943 - val_accuracy: 0.8182 - val_loss: 0.4481\n",
      "Epoch 23/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8211 - loss: 0.3900 - val_accuracy: 0.8182 - val_loss: 0.4496\n",
      "Epoch 24/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8069 - loss: 0.4086 - val_accuracy: 0.8117 - val_loss: 0.4498\n",
      "Epoch 25/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8031 - loss: 0.4365 - val_accuracy: 0.8182 - val_loss: 0.4494\n",
      "Epoch 26/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8320 - loss: 0.3812 - val_accuracy: 0.8182 - val_loss: 0.4501\n",
      "Epoch 27/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8380 - loss: 0.3724 - val_accuracy: 0.8117 - val_loss: 0.4506\n",
      "Epoch 28/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8261 - loss: 0.4014 - val_accuracy: 0.8117 - val_loss: 0.4507\n",
      "Epoch 29/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8153 - loss: 0.4068 - val_accuracy: 0.8117 - val_loss: 0.4512\n",
      "Epoch 30/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8285 - loss: 0.3794 - val_accuracy: 0.8117 - val_loss: 0.4517\n",
      "Epoch 31/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8232 - loss: 0.4138 - val_accuracy: 0.8117 - val_loss: 0.4514\n",
      "Epoch 32/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8162 - loss: 0.4076 - val_accuracy: 0.8247 - val_loss: 0.4496\n",
      "Epoch 33/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8141 - loss: 0.3972 - val_accuracy: 0.8247 - val_loss: 0.4508\n",
      "Epoch 34/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8070 - loss: 0.4279 - val_accuracy: 0.8182 - val_loss: 0.4502\n",
      "Epoch 35/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8141 - loss: 0.3993 - val_accuracy: 0.8182 - val_loss: 0.4486\n",
      "Epoch 36/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8321 - loss: 0.3857 - val_accuracy: 0.8182 - val_loss: 0.4480\n",
      "Epoch 37/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8114 - loss: 0.4089 - val_accuracy: 0.8182 - val_loss: 0.4502\n",
      "Epoch 38/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8070 - loss: 0.4231 - val_accuracy: 0.8117 - val_loss: 0.4503\n",
      "Epoch 39/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8075 - loss: 0.4107 - val_accuracy: 0.8117 - val_loss: 0.4512\n",
      "Epoch 40/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7958 - loss: 0.4221 - val_accuracy: 0.8117 - val_loss: 0.4501\n",
      "Epoch 41/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7929 - loss: 0.4425 - val_accuracy: 0.8182 - val_loss: 0.4497\n",
      "Epoch 42/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8213 - loss: 0.3969 - val_accuracy: 0.8052 - val_loss: 0.4489\n",
      "Epoch 43/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8342 - loss: 0.3731 - val_accuracy: 0.8052 - val_loss: 0.4483\n",
      "Epoch 44/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8131 - loss: 0.4128 - val_accuracy: 0.8117 - val_loss: 0.4499\n",
      "Epoch 45/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8165 - loss: 0.3980 - val_accuracy: 0.8052 - val_loss: 0.4506\n",
      "Epoch 46/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8321 - loss: 0.3804 - val_accuracy: 0.8052 - val_loss: 0.4508\n",
      "Epoch 47/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8305 - loss: 0.4021 - val_accuracy: 0.8182 - val_loss: 0.4517\n",
      "Epoch 48/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8021 - loss: 0.4373 - val_accuracy: 0.8182 - val_loss: 0.4517\n",
      "Epoch 49/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8278 - loss: 0.3925 - val_accuracy: 0.8117 - val_loss: 0.4500\n",
      "Epoch 50/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8117 - loss: 0.4347 - val_accuracy: 0.8117 - val_loss: 0.4492\n",
      "Epoch 51/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8168 - loss: 0.3996 - val_accuracy: 0.8182 - val_loss: 0.4497\n",
      "Epoch 52/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8374 - loss: 0.4129 - val_accuracy: 0.8052 - val_loss: 0.4502\n",
      "Epoch 53/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8405 - loss: 0.3840 - val_accuracy: 0.8052 - val_loss: 0.4498\n",
      "Epoch 54/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8046 - loss: 0.4234 - val_accuracy: 0.8052 - val_loss: 0.4514\n",
      "Epoch 55/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8423 - loss: 0.3808 - val_accuracy: 0.8117 - val_loss: 0.4505\n",
      "Epoch 56/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8442 - loss: 0.3749 - val_accuracy: 0.8182 - val_loss: 0.4526\n",
      "Epoch 57/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8428 - loss: 0.3914 - val_accuracy: 0.8182 - val_loss: 0.4511\n",
      "Epoch 58/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8492 - loss: 0.3659 - val_accuracy: 0.8117 - val_loss: 0.4526\n",
      "Epoch 59/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8091 - loss: 0.4071 - val_accuracy: 0.8052 - val_loss: 0.4522\n",
      "Epoch 60/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8193 - loss: 0.4006 - val_accuracy: 0.8052 - val_loss: 0.4502\n",
      "Epoch 61/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8250 - loss: 0.3981 - val_accuracy: 0.8117 - val_loss: 0.4499\n",
      "Epoch 62/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8251 - loss: 0.3859 - val_accuracy: 0.8117 - val_loss: 0.4498\n",
      "Epoch 63/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8201 - loss: 0.3904 - val_accuracy: 0.8182 - val_loss: 0.4514\n",
      "Epoch 64/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8343 - loss: 0.3918 - val_accuracy: 0.8117 - val_loss: 0.4501\n",
      "Epoch 65/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8249 - loss: 0.3766 - val_accuracy: 0.8052 - val_loss: 0.4489\n",
      "Epoch 66/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8293 - loss: 0.3783 - val_accuracy: 0.8182 - val_loss: 0.4530\n",
      "Epoch 67/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8452 - loss: 0.3599 - val_accuracy: 0.8182 - val_loss: 0.4515\n",
      "Epoch 68/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8326 - loss: 0.3820 - val_accuracy: 0.8247 - val_loss: 0.4516\n",
      "Epoch 69/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8152 - loss: 0.4163 - val_accuracy: 0.8117 - val_loss: 0.4481\n",
      "Epoch 70/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8206 - loss: 0.4111 - val_accuracy: 0.8052 - val_loss: 0.4486\n",
      "Epoch 71/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8192 - loss: 0.4105 - val_accuracy: 0.8052 - val_loss: 0.4498\n",
      "Epoch 72/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8189 - loss: 0.4174 - val_accuracy: 0.8052 - val_loss: 0.4491\n",
      "Epoch 73/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8333 - loss: 0.3936 - val_accuracy: 0.8052 - val_loss: 0.4495\n",
      "Epoch 74/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8277 - loss: 0.3810 - val_accuracy: 0.8052 - val_loss: 0.4494\n",
      "Epoch 75/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8328 - loss: 0.3852 - val_accuracy: 0.8117 - val_loss: 0.4494\n",
      "Epoch 76/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8361 - loss: 0.3861 - val_accuracy: 0.8117 - val_loss: 0.4495\n",
      "Epoch 77/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8400 - loss: 0.3859 - val_accuracy: 0.8117 - val_loss: 0.4498\n",
      "Epoch 78/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8047 - loss: 0.4076 - val_accuracy: 0.8052 - val_loss: 0.4502\n",
      "Epoch 79/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8361 - loss: 0.3854 - val_accuracy: 0.8117 - val_loss: 0.4519\n",
      "Epoch 80/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8500 - loss: 0.3837 - val_accuracy: 0.8052 - val_loss: 0.4518\n",
      "Epoch 81/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8310 - loss: 0.3886 - val_accuracy: 0.8117 - val_loss: 0.4503\n",
      "Epoch 82/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8375 - loss: 0.3922 - val_accuracy: 0.8117 - val_loss: 0.4498\n",
      "Epoch 83/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8218 - loss: 0.4184 - val_accuracy: 0.8182 - val_loss: 0.4521\n",
      "Epoch 84/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8263 - loss: 0.4091 - val_accuracy: 0.8117 - val_loss: 0.4523\n",
      "Epoch 85/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8227 - loss: 0.3844 - val_accuracy: 0.8052 - val_loss: 0.4518\n",
      "Epoch 86/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8162 - loss: 0.3816 - val_accuracy: 0.8052 - val_loss: 0.4517\n",
      "Epoch 87/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8358 - loss: 0.3887 - val_accuracy: 0.8117 - val_loss: 0.4511\n",
      "Epoch 88/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8436 - loss: 0.3761 - val_accuracy: 0.8052 - val_loss: 0.4525\n",
      "Epoch 89/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8397 - loss: 0.3773 - val_accuracy: 0.8182 - val_loss: 0.4523\n",
      "Epoch 90/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8269 - loss: 0.3870 - val_accuracy: 0.8117 - val_loss: 0.4522\n",
      "Epoch 91/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8414 - loss: 0.3755 - val_accuracy: 0.8182 - val_loss: 0.4520\n",
      "Epoch 92/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8175 - loss: 0.3923 - val_accuracy: 0.8182 - val_loss: 0.4535\n",
      "Epoch 93/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8192 - loss: 0.4189 - val_accuracy: 0.8182 - val_loss: 0.4534\n",
      "Epoch 94/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8248 - loss: 0.3993 - val_accuracy: 0.8182 - val_loss: 0.4539\n",
      "Epoch 95/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8499 - loss: 0.3704 - val_accuracy: 0.8117 - val_loss: 0.4561\n",
      "Epoch 96/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8356 - loss: 0.3819 - val_accuracy: 0.8117 - val_loss: 0.4554\n",
      "Epoch 97/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8273 - loss: 0.3963 - val_accuracy: 0.8052 - val_loss: 0.4540\n",
      "Epoch 98/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8435 - loss: 0.3655 - val_accuracy: 0.8117 - val_loss: 0.4549\n",
      "Epoch 99/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8310 - loss: 0.4146 - val_accuracy: 0.8052 - val_loss: 0.4537\n",
      "Epoch 100/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8175 - loss: 0.4234 - val_accuracy: 0.8117 - val_loss: 0.4541\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x22c287332b0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,batch_size=32,epochs=100,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF_D",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
